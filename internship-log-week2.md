
# ðŸ§¾ Internship Log â€“ Week 2

**Dates:** May 14 â€“ May 17, 2025

---

### ðŸ“… May 14, 2025

**Total Hours Worked:** 5

---

**Tasks Completed:**

* Spent several hours attempting to implement advanced functionality into the dashboard using ChatGPT
* Encountered significant delays due to performance issues with ChatGPT
* Switched to using Claude for prompt experimentation and API testing
* Initiated research into LM Studio and its local API endpoints
* Outlined initial steps for integrating LM Studio into the project for real-time analysis of simulated and static log files

---

**ðŸ§  Observations & Lessons Learned:**

* AI assistant responsiveness can affect productivity significantly; having a backup model (Claude) is beneficial
* LM Studio has potential to elevate the dashboard from static analysis to real-time LLM-powered threat detection
* Prompting styles differ slightly between LLMs; experimentation required to refine format

---

### ðŸ“… May 15, 2025

**Total Hours Worked:** 4

---

**Tasks Completed:**

* Networked with peers and reviewed Python code collaboratively to deepen understanding of current architecture
* Identified structural inefficiencies and potential areas for better modularity
* Initiated first successful connection tests to a live LM Studio server session
* Encountered and troubleshot various server connection errors related to LM Studio
* Continued planning for how LM Studio would analyze logs and return threat classifications in real time

---

**ðŸ§  Observations & Lessons Learned:**

* Gained stronger command of Python code structure and how current scripts function
* LM Studio integration is complex but promising â€” real-time local inference is viable for this use case
* Peer review and discussion helped reveal blind spots and accelerated problem solving

---

### ðŸ“… May 16, 2025

**Total Hours Worked:** 4

---

**Tasks Completed:**

* Achieved first **successful implementation of LM Studio** with the AI Threat Detection Dashboard
* Configured LM Studio inference settings for stable local use
* Fine-tuned prompts and formatting for optimal log analysis
* Tested log batching via LM Studio and received accurate, readable outputs
* Verified that LM Studio could classify and explain simulated logs as expected

---

**ðŸ§  Observations & Lessons Learned:**

* Prompt engineering is crucial for maintaining structured output and clarity
* Local LLMs (like Studio LM) offer fast, private inference pipelines without cloud latency
* The project has reached a functional milestone â€” real-time AI-assisted log analysis is now operational

---

### ðŸ“… May 17, 2025

**Total Hours Worked:** 9

---

**Tasks Completed:**

* Added significant upgrades to the front end of the dashboard:

  * Dark mode toggle
  * Live LM Studio integration toggle
  * Enhanced table with log-level color coding
  * New controls for file upload and analysis triggers
* Added many new backend capabilities:

  * Unified backend script that generates simulated logs and supports file-based analysis
  * Added log ingestion, LM Studio querying, and response display into a single streamlined pipeline
* Debugged several persistent issues related to file handling, refresh logic, and LLM response parsing
* Optimized analysis processing time and interface responsiveness
* Improved UX with additional feedback and status indicators

---

**ðŸ§  Observations & Lessons Learned:**

* Frontend and backend are now tightly integrated; UI reflects real-time AI insights clearly
* LM Studio can be reliably used as a backend service for local log analysis
* Debugging and code modularization remain time-consuming but essential for a stable user experience

---

**ðŸ“Œ Next Steps:**

* Add search box and timeline filter to UI
* Expand severity-based filtering logic
* Refine the LM Studio API output formatting for better dashboard readability
* Consider adding user feedback buttons to label AI responses as correct/incorrect
* Start planning end-of-project documentation and final demo walkthrough


